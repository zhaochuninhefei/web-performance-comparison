性能测试记录
=====

本文档用于记录`web-performance-comparison`的性能测试过程数据。

# 测试资源

## 宿主机(虚拟机)资源
- CPU : Intel(R) Xeon(R) CPU E5-2609 v3 @ 1.90GHz, 4 core
- 内存 : 16G
- OS : Anolis OS release 8.6
- docker-ce : 20.10.22
- 网卡带宽 : 10000Mb/s

## 客户机(物理机)资源
- CPU : 12th Gen Intel(R) Core(TM) i7-12700H
- 内存 : 32G
- OS : Linux Mint 20.3
- jmeter : 5.1.1
- 网卡带宽 : 1000Mb/s

## 客户机socket连接端口配置调整
为防止高并发时jmeter发生`java.net.noroutetohostexception`异常，对客户机进行如下配置:

```sh
# 查看可用端口号范围
# 这里查看的结果是 `32768	60999`
cat /proc/sys/net/ipv4/ip_local_port_range

# 查看端口释放后的等待时间，这里的结果是60秒
cat /proc/sys/net/ipv4/tcp_fin_timeout

# 调低端口释放后的等待时间，改为30秒
echo 30 > /proc/sys/net/ipv4/tcp_fin_timeout

# 释放超时端口给新连接使用，默认为0，修改为1
echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse

# 或在`/etc/sysctl.conf`中加入以下配置:
#  net.ipv4.tcp_tw_reuse=1
#  net.ipv4.tcp_fin_timeout=30
# 然后执行以下命令生效
sudo sysctl -p

```


# 镜像及空闲时容器资源消耗比较

## 镜像大小比较
`web-pm-go`与`web-pm-java`的镜像大小如下所示：
- `172.17.4.86:5000/web-pm-go:0.0.1` : 21.6 MB
- `172.17.4.86:5000/web-pm-java:0.0.1-SNAPSHOT` : 359.3 MB

可以看到，go的镜像明显比java镜像小一个数量级，但这是有原因的。
1. `web-pm-go`在打镜像时，并没有直接使用`From golang`，而是基于`alpine`，将本地编译好的完整二进制文件直接拷贝进去，因此不需要庞大的gcc等编译需要的库。如果基于`From golang`，在docker编译时再执行二进制文件编译的话，那么go的镜像同样也会有几百兆。
2. java的镜像主要是jdk部分较大，原则上运行时不需要整个jdk，可以用jre缩小镜像，甚至根据模块去除没有使用的依赖包，这样镜像能进一步缩小。但缩小java镜像的意义并不是特别大，而保留完整的jdk则更方便使用jdk的工具包对jvm进行检查或调试。

**结论**

一般来说go的镜像要比java镜像小得多，但其实镜像大小的意义并没有那么大，最多上云的时候多耗费一些网络流量和磁盘空间。

## 空闲时资源消耗比较
首先，在docker编排文件中已经限制了`web-pm-go`与`web-pm-java`的资源上限:
```yaml
    deploy:
      resources:
        limits:
          cpus: '4.00'
          memory: 2048M
        reservations:
          memory: 512M
```
两者限制一样，最多使用4颗CPU，内存占用不能超过2G。

在宿主机使用命令`docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"`查看容器的资源消耗情况如下:
```
NAME          CPU %     MEM USAGE / LIMIT
web-pm-go     0.00%     13.8MiB / 1GiB
web-pm-java   0.11%     230.5MiB / 1GiB
```
可以看到，空闲时`web-pm-go`基本不消耗CPU资源，内存占用也极小，只有十几兆。而`web-pm-java`则始终有少量的CPU消耗，内存占用也比较大，空闲时就有200多兆。

**结论**

空闲时，`go+gin`的资源消耗远小于`java+springboot`。


# 单纯HttpAPI接口的性能测试
本节测试单纯的，没有任何数据库或磁盘读写的HttpAPI接口：
- web-pm-go : "/asset/query"
- web-pm-java : "/asset/query"

## web-pm-go-asset_query

### 300用户2000RPS

容器CPU消耗: 60%

### 500用户3000RPS
测试压力数据:
- 模拟用户线程数 : 500
- 模拟RPS : 3000
- 运行时间 : 120秒

测试期间服务器资源消耗情况:

命令`docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"`的实时情况是，`web-pm-go`的CPU使用率大部分时间在`80%`上下，峰值时超过`100%`，内存有所增加，但基本在20兆以内。

测试期间客户机资源消耗情况: CPU/内存/网络流量均未到上限。


测试结果:

| Label | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max | Error % | Throughput | Received KB/sec | Sent KB/sec |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| HTTP Request asset_query | 334494 | 2 | 1 | 4 | 6 | 22 | 0 | 1038 | 0.000% | 2787.91465 | 473.73 | 0.00 |
| TOTAL | 334494 | 2 | 1 | 4 | 6 | 22 | 0 | 1038 | 0.000% | 2787.91465 | 473.73 | 0.00 |

可以看到，500用户3000RPS的压力下，`web-pm-go`的吞吐量达到`2700+`，响应时间保持在几毫秒的级别。



### 500用户5000RPS

容器CPU消耗: 100%

| Label | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max | Error % | Throughput | Received KB/sec | Sent KB/sec |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| HTTP Request asset_query | 554587 | 2 | 1 | 3 | 4 | 17 | 0 | 1048 | 0.000% | 4622.17462 | 785.41 | 0.00 |
| TOTAL | 554587 | 2 | 1 | 3 | 4 | 17 | 0 | 1048 | 0.000% | 4622.17462 | 785.41 | 0.00 |


### 1000用户10000RPS

容器CPU消耗: 160%

| Label | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max | Error % | Throughput | Received KB/sec | Sent KB/sec |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| HTTP Request asset_query | 1219074 | 8 | 1 | 5 | 14 | 85 | 0 | 3086 | 0.000% | 8709.91112 | 1480.00 | 0.00 |
| TOTAL | 1219074 | 8 | 1 | 5 | 14 | 85 | 0 | 3086 | 0.000% | 8709.91112 | 1480.00 | 0.00 |


## web-pm-java-asset_query
